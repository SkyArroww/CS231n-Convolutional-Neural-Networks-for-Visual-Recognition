# Assignment 2

## Exercise 1. 全连接神经网络 Fully-connected Neural Network

    In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a`forward` and a `backward` function.

    In addition to implementing fully-connected networks of arbitrary depth, we will also explore different update rules for optimization, and introduce Dropout as a regularizer and Batch/Layer Normalization as a tool to more efficiently optimize deep networks.

    正常按照提示实现即可。



## Exercise 2. 批归一化 Batch Normaliztion
